---
title: "Forth and Tay"
author: "Lindesay Scott-Hayward"
date: "18 August 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dev='png', warning=FALSE, message=FALSE, fig=TRUE)
```

```{r fat, echo=FALSE, warning=FALSE, message=FALSE}
devtools::load_all(pkg = '../../../MRSea/MRSea')
devtools::load_all(pkg = '../../../MRSeaPower')
data(fat)
```

# Initial Model Fitting

### Fit Initial Model

Owing to the very low mean, the data are converted to presence/absence data and fitted using the binomial family. The panel column is created to identify each individual transect. 

```{r fatsetup}
# convert data to presence/absence
fat$response<-ifelse(fat$response>0, 1, 0)
fat$panel<-as.numeric(as.factor(paste(fat$survey, fat$trip.code, sep='')))
fat$foldid<-getCVids(fat, 5, 'panel')
```

```{r rawplot, fig.cap='Plot of the data with mean probability of sighting per grid cell.'}
require(fields)
quilt.plot(fat$x.pos, fat$y.pos, fat$response, asp=1)
```


```{r fatinitglm}
init_glm<-glm(response ~ as.factor(year), data=fat, family=binomial)
```


### Run SALSA1D
```{r salsa1d, cache=TRUE}
require(mgcv)
factorlist<-'year'
varlist<-c('depth', 'month', 'x.pos', 'y.pos')

salsa1dlist<-list(fitnessMeasure='AIC', minKnots_1d = c(1,1,1,1), maxKnots_1d=c(5,5,5,5), startKnots_1d = c(1,1,1,1), degree=c(2,2,2,2), maxIterations=100, gaps=c(0,0,100,0))

salsa1dout<-runSALSA1D_withremoval(init_glm, salsa1dlist, varlist, factorlist, varlist_cyclicSplines = c('month'), splineParams = NULL, datain=fat)

```

```{r}
summary(salsa1dout$bestModel, varshortnames=varlist)
anova(salsa1dout$bestModel, varshortnames=varlist)

```

Depth is not significant so this is removed from the model and the process repeated:
  
```{r salsa1db, cache=TRUE}
factorlist<-'year'
varlist<-c('month', 'x.pos', 'y.pos')

salsa1dlist<-list(fitnessMeasure='AIC', minKnots_1d = c(1,1,1), maxKnots_1d=c(5,5,5), startKnots_1d = c(1,1,1), degree=c(2,2,2), maxIterations=100, gaps=c(0,100,0))

salsa1dout<-runSALSA1D_withremoval(init_glm, salsa1dlist, varlist, factorlist, varlist_cyclicSplines = c('month'), splineParams = NULL, datain=fat)
```

```{r}
summary(salsa1dout$bestModel, varshortnames=varlist)
anova(salsa1dout$bestModel, varshortnames=varlist)
```


```{r}
bestModel<-make.gamMRSea(salsa1dout$bestModel, panelid = fat$panel, splineParams = salsa1dout$splineParams, varshortnames = varlist)
splineParams<-bestModel$splineParams
```


```{r}
require(mgcv)
runPartialPlots(bestModel, data = fat, factorlist.in = factorlist, varlist.in = varlist, showKnots = T)
```


### Runs Test Check

Data generated under the null hypothesis of the runs test; independence and with no change induced at this stage.

```{r fatnoise}
nsim<-500
newdat<-generateNoise(nsim, fitted(bestModel), family='zibinomial', size=1)
```

`r nsim` sets of noisy data are simulated from the model using an overdispersed Poisson distribution where $\hat{\phi} = $ `r round(summary(init_glm)$dispersion)`.

```{r critvalsfat, cache=T, fig.cap='Figure showing the distribution of test statistics from a runs test. The red lines show the lower 2.5% and upper 97.5% critical values of the empirical distribution and the blue lines are from the Normal ($N(0,1)$) distribution.'}
empdistribution<-getRunsCritVals(n.sim = nsim, simData=newdat, 
                                 model = bestModel, data = fat, plot=TRUE, 
                                 returnDist = TRUE, dots=FALSE)
```

Evaluate the runs test using the empirical distribution to determine if the data are independent
```{r runsacffat}
runs.test(residuals(bestModel, type='pearson'), critvals = empdistribution)
acf(residuals(bestModel, type='pearson'))
```

The residuals are considered independent so for the power analysis, the data will be generated as independent as already done. 

# Data Generation

Data are generated with no change but with the same correlation as the original data so that the data generation process can be checked.

Even though the data are considered independent, the following generates data with the same correlation structure and shows that the IC method does not induce correlation in the simulated data. 

```{r cordatfat, cache=TRUE}
corrs<-getCorrelationMat(fat$panel, fat$response, dots=FALSE)
newdatcor<-generateIC(data = fat, corrs = corrs, panels = 'panel', newdata = newdat, nsim = nsim, dots = FALSE)
```

```{r acfplot}
par(mfrow=c(1,2))
acf(fat$response, main='data')
acf(newdatcor[,1], main='simulated data')
```

### Check simulated data consistency

The generated data are consistent with the original data:
  
#### Mean
```{r meanplotfat, fig.cap='Histogram of the mean of the simulated data, with the red line representing the mean of the original data.'}
hist(apply(newdat, 2, mean), main='', xlab='mean(response)')
abline(v=mean(fat$response), col='red', lwd=2, lty=3)
```

#### Variance
```{r varplotfat, fig.cap='Histogram of the variance of the simulated data, with the red line representing the variance of the original data.'}
hist(apply(newdat, 2, var), main='', xlab='var(response)')
abline(v=var(fat$response), col='red', lwd=2, lty=3)
var(fat$response)
```

#### Data distribution

```{r datadistributionfat, fig.cap='Figure showing the spatial distribution of the original data, the fitted values from the model and two examples of the simulated data.'}
par(mfrow=c(2,2))
quilt.plot(fat$x.pos, fat$y.pos, fat$response, main='Original Data', asp=1)
quilt.plot(fat$x.pos, fat$y.pos, fitted(bestModel), main='Fitted Values', asp=1)
quilt.plot(fat$x.pos, fat$y.pos, newdat[,1], main='Simulated Data A', asp=1)
quilt.plot(fat$x.pos, fat$y.pos, newdat[,10], main='Simulated Data B', asp=1)
```


# Power Analysis

Generate data for power analysis with impact of 50\%

```{r powerdatgenfat, cache=TRUE}
nsim=500
impdata<-genOverallchangeData(-0.69, bestModel, data = fat, panels = 'panel')
newdat<-generateNoise(nsim, impdata$truth, family='zibinomial', size=1)
```

Check the generated data has reduced the mean probability of sighting post impact by half:
  
```{r}
# original data
mean(fat$response)
# fitted value mean
mean(fitted(bestModel))
```

```{r}
# true surface
mean(impdata$truth[impdata$eventphase==0,1])
mean(impdata$truth[impdata$eventphase==1,1])
```

```{r}
# example generated surface
mean(newdat[impdata$eventphase==0,1])
mean(newdat[impdata$eventphase==1,1])
```

Update the initial model to include the eventphase term, indicating overall change.

```{r}
require(mgcv)
fatsim_glm<-update(bestModel, .~. + eventphase, data=impdata)
```

Using the simulated data with noise but no correlation, estimate the new values for the empirical distribution for the runs test.

```{r empdistpower, cache=TRUE}
# make sure that the independent data is used to get the null distribution
empdistpower<-getRunsCritVals(n.sim = nsim, simData=newdat, 
                              model = fatsim_glm, data = impdata, plot=TRUE, 
                              returnDist = TRUE, dots=FALSE)
```


```{r, powerouta, cache=TRUE, echo=FALSE, eval=FALSE}
runspowsim_out<-runsPowerSim(newdat, fatsim_glm, empdistpower, nsim, powercoefid = length(coef(fatsim_glm)))

apply(runspowsim_out$rawrob, 2, sum)/nsim

(length(which(runspowsim_out$imppvals[,1]<=0.05))/nsim)*100
(length(which(runspowsim_out$imppvals[,2]<=0.05))/nsim)*100

```

```{r gridsetup, cache=TRUE}
grid<-expand.grid(seq(min(fat$x.pos), max(fat$x.pos), by=1000), seq(min(fat$y.pos), max(fat$y.pos), by=1000))
names(grid)<-c('x.pos', 'y.pos')

bnd<-cbind(fat$x.pos, fat$y.pos)[chull(x = fat$x.pos, fat$y.pos),]
require(splancs)
gridsub<-grid[inout(grid, bnd),]

predictdata<-rbind(data.frame(gridsub, month=9, year=2011, eventphase=0), data.frame(gridsub, month=9, year=2011, eventphase=1))
```

```{r poweroutfat, cache=TRUE, dependson='gridsetup'}
nsim=100

powerout<-powerSimOverallChange(newdat, fatsim_glm, empdistpower, nsim=nsim, powercoefid=length(coef(fatsim_glm)), predictionGrid=predictdata, g2k=NULL, splineParams=bestModel$splineParams, sigdif=TRUE, n.boot=500, impact.loc=c(570000, 6240000))
```

# Power Outputs:


## Summary output

```{r nulloutput, cache=TRUE}
null.output<-pval.coverage.null(newdat.ind = newdat, model = fatsim_glm, nsim = 500, powercoefid = length(coef(fatsim_glm)))
```

```{r}
summary(powerout, null.output, truebeta=-0.69)

```


### Proportion of significant differences:
```{r sigdiff.ind,, fig.cap='Figure showing the proportion of simulations which showed a significant difference (post event - pre event) in a given grid cell. Significance at the 5% level was determined by comparing the estimated difference in a given cell to the distribution of differences in that cell under the null hypothesis of no-change.'}
plotdata<-plot.sigdiff(powerout, predictdata[predictdata$eventphase==0,c('x.pos', 'y.pos')], tailed='two', error.rate = 0.05, family=FALSE)
plotdata
```

```{r sigdiff.famfat, fig.cap='Figure showing the proportion of simulations which showed a significant difference (post event - pre event) in a given grid cell. Significance at the 5% level was determined by comparing the estimated difference in a given cell to the distribution of differences across all grid cells under the null hypothesis of no-change.'}
plotdata<-plot.sigdiff(powerout, predictdata[predictdata$eventphase==0,c('x.pos', 'y.pos')], tailed='two', error.rate = 0.05, family=TRUE)
plotdata
```

### Distance to event site plot

```{r disttoimpfat, fig.cap='Figure showing the effect of the event on animal numbers with distance from the event site; post event - pre event.  The confidence intervals are 95% bootstrap intervals.'}
d2impPlot<-plot.d2imp(powerout)
d2impPlot
```

```{r}
#lazyLoad(filebase = 'FoWPower_cache/html/poweroutfow_e9cd6eba643105e8af4b9b2a338149a2')
```
