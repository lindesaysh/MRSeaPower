---
title: 'Fall of Warness Power: Spatial'
author: "Lindesay Scott-Hayward"
date: "23 August 2016"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig=TRUE, dev='png', warning=FALSE, message=FALSE)
```
# Real Data: Falls of Warness

```{r fow, echo=FALSE}
#devtools::load_all(pkg = '../../../../Packages/MRSea package/MRSea')
devtools::load_all(pkg = '../../../MRSea/MRSea')
devtools::load_all(pkg = '../../../MRSeaPower')
require(mgcv)
require(splines)
data(fowshco)
```

### Fit Initial Model
```{r fowinitglm}
init_glm<-glm(response ~  as.factor(TideState) + as.factor(WindStrength) + as.factor(SeaState) + as.factor(SimpPrecipitation) + as.factor(CloudCover) + offset(log(areatime)), data=dat, family=quasipoisson)
```


### Run SALSA1D
```{r salsa1d, cache=TRUE}
factorlist<-c('TideState', 'WindStrength','SeaState',  'SimpPrecipitation', 'CloudCover')
varlist<-c('Depth', 'MonthInt')

salsa1dlist<-list(fitnessMeasure='QAIC', minKnots_1d = c(1,1), maxKnots_1d=c(5,5), startKnots_1d = c(1,1), degree=c(2,2), maxIterations=100, gaps=c(0,0))

salsa1dout<-runSALSA1D_withremoval(init_glm, salsa1dlist, varlist, factorlist, varlist_cyclicSplines = c('MonthInt'), splineParams = NULL, datain=dat, suppress.printout = TRUE)

salsa1dout$bestModel$splineParams<-salsa1dout$splineParams

```

```{r inter1d, cache=TRUE}
salsa1dout$bestModel<-make.gamMRSea(salsa1dout$bestModel, panelid = dat$newbid, splineParams = salsa1dout$splineParams)
#splineParams<-bestModel1D$splineParams
```

```{r}
summary(salsa1dout$bestModel)

anova(salsa1dout$bestModel)

```

Tide state is not significant so this is removed from the model and the process repeated:
  
```{r salsa1db, cache=TRUE}
init_glm<-glm(response ~  as.factor(WindStrength) + as.factor(SeaState) + as.factor(SimpPrecipitation) + as.factor(CloudCover) + offset(log(areatime)), data=dat, family=quasipoisson)

factorlist<-c('WindStrength','SeaState',  'SimpPrecipitation', 'CloudCover')
varlist<-c('Depth', 'MonthInt')

salsa1dlist<-list(fitnessMeasure='QAIC', minKnots_1d = c(1,1), maxKnots_1d=c(5,5), startKnots_1d = c(1,1), degree=c(2,2), maxIterations=100, gaps=c(0,0))

salsa1dout<-runSALSA1D_withremoval(init_glm, salsa1dlist, varlist, factorlist, varlist_cyclicSplines = c('MonthInt'), splineParams = NULL, datain=dat,suppress.printout=TRUE)
```

```{r best1d, cache=TRUE}
bestModel1D<-make.gamMRSea(salsa1dout$bestModel, panelid = dat$newbid, splineParams = salsa1dout$splineParams)
#splineParams<-bestModel1D$splineParams
```

```{r}
summary(salsa1dout$bestModel)
anova(salsa1dout$bestModel)
```


```{r}
runPartialPlots(bestModel1D, data = dat, factorlist.in = factorlist, varlist.in = varlist, showKnots = T)
```


### Run SALSA2D

```{r salsa2dsetup, cache=TRUE}
knotgrid<-getKnotgrid(cbind(dat$x.pos, dat$y.pos))
distMats<-makeDists(cbind(dat$x.pos, dat$y.pos), na.omit(knotgrid))
# choose sequence of radii
r_seq<-getRadiiChoices(8, distMats$dataDist)
 
salsa2dlist<-list(fitnessMeasure = 'QAIC', knotgrid = knotgrid, knotdim = c(100, 100),  startKnots=2, minKnots=2, maxKnots=20, r_seq=r_seq, gap=0)
```

```{r runsalsa2d, cache=TRUE}
salsa2dOutput<-runSALSA2D(bestModel1D, salsa2dlist, d2k=distMats$dataDist, k2k=distMats$knotDist, splineParams=salsa1dout$splineParams, tol=0, chooserad=F, panels=NULL, suppress.printout=TRUE)
```

```{r}
bestModel<-make.gamMRSea(salsa2dOutput$bestModel, panelid = dat$newbid, splineParams = salsa2dOutput$splineParams, varshortnames = varlist, gamMRSea=TRUE)

rm(splineParams, dists)
```

```{r}
summary(bestModel)
anova(bestModel)
```

```{r}
save(bestModel, file='FoW_model.RData')
```


### Runs Test Check

Data generated under the null hypothesis of the runs test; independence and with no change induced at this stage.

```{r fownoise}
nsim<-500
d<-as.numeric(summary(bestModel)$dispersion)
newdat<-generateNoise(nsim, fitted(bestModel), family='poisson', d=d)
```

`r nsim` sets of noisy data are simulated from the model using an overdispersed Poisson distribution where $\hat{\phi} = $ `r round(summary(init_glm)$dispersion)`.

```{r critvalsfow, cache=T, fig.cap='Figure showing the distribution of test statistics from a runs test. The red lines show the lower 2.5% and upper 97.5% critical values of the empirical distribution and the blue lines are from the Normal ($N(0,1)$) distribution.'}
empdistribution<-getRunsCritVals(n.sim = nsim, simData=newdata.fow, 
                                 model = bestModel, data = dat, plot=TRUE, 
                                 returnDist = TRUE, dots=FALSE)
```

Evaluate the runs test using the empirical distribution to determine if the data are independent
```{r runsacffow}
runs.test(residuals(bestModel, type='pearson'), critvals = empdistribution)
acf(residuals(bestModel, type='pearson'))
```

The residuals are considered independent so for the power analysis, the data will be generated as independent. 

### Data Generation

<!-- Data are generated with no change but with the same dispersion and correlation as the original data so that the data generation process can be checked. -->

```{r cordatfow, cache=TRUE, eval=FALSE, echo=FALSE}
corrs<-getCorrelationMat(dat$blockid, dat$response, dots=FALSE)
newdatcor<-generateIC(data = dat, corrs = corrs, panels = 'blockid', newdata = newdat, nsim = nsim, dots = FALSE)
```

Are the generated data consistent with the original data?

#### Mean
```{r meanplotfowsp, fig.cap='Histogram of the mean of the simulated data, with the red line representing the mean of the original data.'}
hist(apply(newdat, 2, mean), main='', xlab='mean(response)')
abline(v=mean(dat$response), col='red', lwd=2, lty=3)
```

#### Variance
```{r varplotfowsp, fig.cap='Histogram of the variance of the simulated data, with the red line representing the variance of the original data.'}
hist(apply(newdat, 2, var), main='', xlab='var(response)')
abline(v=var(dat$response), col='red', lwd=2, lty=3)
var(dat$response)
```

#### Correlation

```{r acffowsp}
par(mfrow=c(1,2))
acf(dat$response, main='Data')
acf(newdat[,50], main='Sim Data')
```

#### Check the dispersion parameter

```{r}
fowsim_glm<-update(bestModel, newdat[,1] ~ .)
summary(fowsim_glm)$dispersion
```

#### Data distribution

```{r datadistfowsp, fig.cap='Figure showing the spatial distribution of the original data, the fitted values from the model and two examples of the simulated data.'}
require(fields)
par(mfrow=c(2,2))
quilt.plot(dat$x.pos, dat$y.pos, dat$response, main='Original Data', nrow=18, ncol=14, asp=1)
quilt.plot(dat$x.pos, dat$y.pos, fitted(init_glm), main='Fitted Values', nrow=18, ncol=14, asp=1)
quilt.plot(dat$x.pos, dat$y.pos, newdat[,1], main='Simulated Data A', nrow=18, ncol=14, asp=1)
quilt.plot(dat$x.pos, dat$y.pos, newdat[,10], main='Simulated Data B', nrow=18, ncol=14, asp=1)
```

### Power Analysis

Generate data for power analysis with impact of 50\%

```{r powerdatgen, cache=TRUE}
nsim=500
impdata<-genOverallchangeData(log(0.5), bestModel, data = dat, panels = 'newbidNum')
newdat<-generateNoise(nsim, impdata$truth, family='poisson', d=d)
```

```{r}
sum(newdat[impdata$eventphase==0,1])
sum(newdat[impdata$eventphase==1,1])
```

Update the initial model to include the eventphase term, indicating overall change.

```{r}
bestModel$splineParams[[1]]$dist<-rbind(bestModel$splineParams[[1]]$dist, bestModel$splineParams[[1]]$dist)
fowsim_glm<-update(bestModel, newdat[,1]~. + eventphase, data=impdata)
fowsim_glm$panels<-impdata$panels
```

Using the simulated data with noise but no correlation, estimate the new values for the empirical distribution for the runs test.

```{r empdistpower, cache=TRUE}
# make sure that the independent data is used to get the null distribution
empdistpower<-getRunsCritVals(n.sim = nsim, simData=newdat, 
                                 model = fowsim_glm, data = impdata, plot=TRUE, 
                                 returnDist = TRUE, dots=FALSE)
```


If an offset is present in the model, when setting up the prediction grid the area of each gridcell should be provided so that an accurate estimate of the abundance can be made at the outputs stage. 

```{r predgridsetup}
data("fowshco.grid")
predictdata<-rbind(data.frame(fowshco.grid, TideState=1, WindStrength=0, SeaState=1, SimpPrecipitation='NONE', CloudCover=7, MonthInt=6, areatime=fowshco.grid$Area, eventphase=0), data.frame(fowshco.grid, TideState=1, WindStrength=0, SeaState=1, SimpPrecipitation='NONE', CloudCover=7, MonthInt=6,areatime=fowshco.grid$Area, eventphase=1))

g2k<-makeDists(cbind(predictdata$x.pos, predictdata$y.pos), knotcoords = na.omit(knotgrid), knotmat = FALSE)$dataDist
```

```{r poweroutfow, cache=TRUE, dependson='predgridsetup'}
nsim=100
system.time(
powerout<-powerSimOverallChange(newdat, fowsim_glm, empdistpower, nsim=nsim, powercoefid=length(coef(fowsim_glm)), predictionGrid=predictdata, g2k=g2k, splineParams=fowsim_glm$splineParams, sigdif=TRUE, n.boot=500, impact.loc=c(510700, 6555700))
)
```

# Power Outputs:

To calculate the summary, the values for certain parameters are given under the null hypothesis of 'no change'.  If these parameters are not provided, then the summary will not show the comparisons (see below)

### Summary output

```{r}
summary(powerout, truebeta=log(0.5))
```

In order to assess the summary calculations, we estimate the null parameters to provide the full summary. 

```{r nulloutput, cache=TRUE}
null.output<-pval.coverage.null(newdat.ind = newdat, newdat.corr = NULL, model = fowsim_glm, nsim = 500, powercoefid = length(coef(fowsim_glm)))
```

```{r}
summary(powerout, null.output, truebeta=log(0.5))
```

We expect to see the null power to be 5\%, indicating a 5\% error rate for inclusion of the eventphase term when the data do not contain any change.  We also expect that the coverage for the null coefficient is 95\%.  This indicates that 5\% of the time, the confidence intervals for the eventphase coefficient did not include the truth (0; no change).



### How does power change with the error rate?

```{r powerplotfow, fig.cap='Figure showing how the power changes if the error rate is changed.  The dotted lines represent error rates of 0.01 and 0.05.', dependson='poweroutfow'}
powerPlot(powerout)
```


### Proportion of significant differences:
```{r sigdiff.ind, fig.cap='Figure showing the proportion of simulations which showed a significant difference (post event - pre event) in a given grid cell. Significance at the 5% level was determined by comparing the estimated difference in a given cell to the distribution of differences in that cell under the null hypothesis of no-change.'}
plotdata<-plot.sigdiff(powerout, predictdata[predictdata$eventphase==0,c('x.pos', 'y.pos')], tailed='two', error.rate = 0.05, family=FALSE)
plotdata
```

```{r sigdiff.fam, fig.cap='Figure showing the proportion of simulations which showed a significant difference (post event - pre event) in a given grid cell. Significance at the family 5% level was determined by using the Sidak adjustment.'}
plotdata<-plot.sigdiff(powerout, predictdata[predictdata$eventphase==0,c('x.pos', 'y.pos')], tailed='two', error.rate = 0.05, family=TRUE)
plotdata
```

### Distance to event site plot

```{r disttoimp, fig.cap='Figure showing the effect of the event on animal numbers with distance from the event site; post event - pre event.  The confidence intervals are 95% bootstrap intervals.'}
d2impPlot<-plot.d2imp(powerout)
d2impPlot
```

```{r disttoimppct, fig.cap='Figure showing the effect of the event on animal numbers with distance from the event site; post event - pre event.  The confidence intervals are 95% bootstrap intervals.'}
d2impPlot<-plot.d2imp(powerout, pct.diff = TRUE)

d2impPlot
```


```{r, echo=FALSE, eval=FALSE}
lazyLoad(filebase = 'Fow_spatial_oc_cache/docx/inter1d_c5da32629ab0fc740251f62d7199ce00')
```
